{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入库以及库的初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import words\n",
    "import re\n",
    "from tqdm import tqdm \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "legal_words=words.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据  \n",
    "- 读取数据至all_data以列表形式存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=[]\n",
    "all_tweets_id=[]\n",
    "f=open('./data/tweets.txt','r')\n",
    "for line in f:\n",
    "    tweets.append(json.loads(line))\n",
    "    all_tweets_id.append(int(tweets[-1]['tweetId']))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对文本进行预处理的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_text(text:str):\n",
    "    text=text.lower()#均转换为小写\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)#仅保留字母和空格  \n",
    "    tokens=word_tokenize(text)#获取分词结果  \n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    filterd_tokens=[word for word in tokens if word not in stop_words]#去除停用词\n",
    "    lemmatizer_tokens=[lemmatizer.lemmatize(word) for word in filterd_tokens]#还原词形\n",
    "    #lemmatizer_tokens=[word for word in lemmatizer_tokens if word in legal_words]#只保留合法单词，加上这个跑得很慢\n",
    "    return lemmatizer_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成标记序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30364/30364 [00:18<00:00, 1611.20it/s]\n"
     ]
    }
   ],
   "source": [
    "sign_sequence=[]\n",
    "for tweet in tqdm(tweets):\n",
    "    words=[]\n",
    "    words+=deal_text(tweet['userName'])\n",
    "    words+=deal_text(tweet['text'])\n",
    "    for word in words:\n",
    "        sign_sequence.append((word,int(tweet['tweetId'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mariah', 28965792812892160),\n",
       " ('people', 28965792812892160),\n",
       " ('house', 28965792812892160),\n",
       " ('may', 28965792812892160),\n",
       " ('kill', 28965792812892160),\n",
       " ('arizonastyle', 28965792812892160),\n",
       " ('immigration', 28965792812892160),\n",
       " ('bill', 28965792812892160),\n",
       " ('rep', 28965792812892160),\n",
       " ('rick', 28965792812892160)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_sequence[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 排序  \n",
    "- 按术语排列，然后按照文档ID排序  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sign_sequence=list(set(sign_sequence))\n",
    "unique_sign_sequence.sort(key=lambda x:(x[0],x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aa', 32858841427214336),\n",
       " ('aa', 299786729190219776),\n",
       " ('aa', 302033886265892864),\n",
       " ('aa', 302047903625654273),\n",
       " ('aa', 302101154517643264),\n",
       " ('aa', 302187951440404482),\n",
       " ('aa', 302403580630011906),\n",
       " ('aa', 303810647982997504),\n",
       " ('aa', 306788066926944256),\n",
       " ('aa', 307509260751892480)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_sign_sequence[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字典和倒排索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aa', 32858841427214336),\n",
       " ('aa', 299786729190219776),\n",
       " ('aa', 302033886265892864),\n",
       " ('aa', 302047903625654273),\n",
       " ('aa', 302101154517643264),\n",
       " ('aa', 302187951440404482),\n",
       " ('aa', 302403580630011906),\n",
       " ('aa', 303810647982997504),\n",
       " ('aa', 306788066926944256),\n",
       " ('aa', 307509260751892480)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_sign_sequence[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_dict={}\n",
    "for word in unique_sign_sequence:\n",
    "    if(word[0] in keyword_dict):\n",
    "        keyword_dict[word[0]].append(word[1])\n",
    "    else:\n",
    "        keyword_dict[word[0]]=[word[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29255276477554689,\n",
       " 29902841330012160,\n",
       " 30022191554764802,\n",
       " 31655260195921921,\n",
       " 31811330562334720,\n",
       " 32547752923635712,\n",
       " 32579490752241664,\n",
       " 33962846387707904,\n",
       " 34397865757384705,\n",
       " 34530272498163713]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_dict['dog'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 布尔查询实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_and(keyword1,keyword2):\n",
    "    result=[]\n",
    "    if(keyword1 not in keyword_dict or keyword2 not in keyword_dict):\n",
    "        return result \n",
    "    else:\n",
    "        list1=keyword_dict[keyword1]\n",
    "        list2=keyword_dict[keyword2]\n",
    "        p1=0\n",
    "        p2=0\n",
    "        while(True):\n",
    "            if(p1==len(list1) or p2==len(list2)):\n",
    "                break \n",
    "            if(list1[p1]==list2[p2]):\n",
    "                result.append(list1[p1])\n",
    "                p1+=1\n",
    "                p2+=1\n",
    "            else:\n",
    "                if(list1[p1]>=list2[p2]):\n",
    "                    p2+=1\n",
    "                else:\n",
    "                    p1+=1\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#验证\n",
    "test=op_and('dog','cat')\n",
    "dog=keyword_dict['dog']\n",
    "cat=keyword_dict['cat']\n",
    "for id in test:\n",
    "    if(id not in cat or id not in dog):\n",
    "        print('False')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_or(keyword1,keyword2):\n",
    "    result=[]\n",
    "    if(keyword1 not in keyword_dict and keyword2 not in keyword_dict):\n",
    "        return result \n",
    "    else:\n",
    "        list1=keyword_dict[keyword1]\n",
    "        list2=keyword_dict[keyword2]\n",
    "        p1=0\n",
    "        p2=0\n",
    "        while(True):\n",
    "            if(p1==len(list1) or p2==len(list2)):\n",
    "                break  \n",
    "            if(list1[p1]>=list2[p2]):#如果第一个比第二个大，先放第二个\n",
    "                result.append(list2[p2])\n",
    "                p2+=1\n",
    "            else:\n",
    "                result.append(list1[p1])\n",
    "                p1+=1\n",
    "        result+=list1[p1:]\n",
    "        result+=list2[p2:]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#验证\n",
    "test=op_or('dog','cat')\n",
    "dog=keyword_dict['dog']\n",
    "cat=keyword_dict['cat']\n",
    "sorted(list(set(test)))==sorted(list(set(dog+cat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_not(keyword):\n",
    "    if(keyword not in keyword_dict):\n",
    "        return all_tweets_id\n",
    "    else:\n",
    "        return [i for i in all_tweets_id if i not in keyword_dict[keyword]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#验证\n",
    "test=op_not('dog')\n",
    "dog=keyword_dict['dog']\n",
    "for i in test:\n",
    "    if(i in dog):\n",
    "        print('False')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## and not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_and_not(keyword1,keyword2):\n",
    "    result=[]\n",
    "    if(keyword1 not in keyword_dict):\n",
    "        return result  \n",
    "    else:\n",
    "        list1=keyword_dict[keyword1]\n",
    "        list2=keyword_dict[keyword2]\n",
    "        p1=0\n",
    "        p2=0\n",
    "        while(p1<len(list1)):\n",
    "            id=list1[p1]\n",
    "            p1+=1  \n",
    "            while(p2<len(list2) and list2[p2]<id):\n",
    "                p2+=1\n",
    "            if(p2<len(list2) and list2[p2]==id):\n",
    "                continue \n",
    "            else:\n",
    "                result.append(id)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#验证\n",
    "test=op_and_not('dog','cat')\n",
    "dog=keyword_dict['dog']\n",
    "cat=keyword_dict['cat']\n",
    "sorted(list(set(test+cat)))==sorted(list(set(dog+cat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_word(word:str):\n",
    "    word=word.lower()\n",
    "    word=re.sub(r'[^a-z]','',word)\n",
    "    word=lemmatizer.lemmatize(word)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deal', 'fuck']\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    query=input('>>')\n",
    "    queries=query.split(' ')\n",
    "    if(queries[0]=='NOT'):\n",
    "        print(op_not(deal_word(queries[1])))\n",
    "    elif(queries[1]=='AND'):\n",
    "        print(op_and(deal_word(queries[0]),deal_word(queries[2])))\n",
    "    elif(queries[1]=='OR'):\n",
    "        print(op_or(deal_word(queries[0]),deal_word(queries[2])))\n",
    "    elif(queries[1]=='AND' and queries[2]=='NOT'):\n",
    "        print(op_and_not(deal_word(queries[0]),deal_word(queries[4])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
